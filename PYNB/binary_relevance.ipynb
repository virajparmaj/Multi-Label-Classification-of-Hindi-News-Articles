{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'function'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunction\u001b[39;00m \u001b[39mimport\u001b[39;00m punctuations, score, load_stopwords\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiLabelBinarizer\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'function'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from function import punctuations, score, load_stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Load stopwords from a csv file and store them in a list\n",
        "stopwords = load_stopwords(\"stopwords.csv\")\n",
        "\n",
        "# add punctuations in the list of stopwords\n",
        "stopwords.extend(punctuations)\n",
        "\n",
        "# get dataframe for the dataset\n",
        "try:\n",
        "    dataset = pd.read_excel(\"preprocessed_data_new.xlsx\")\n",
        "except FileNotFoundError as e:\n",
        "    raise Exception(e)\n",
        "\n",
        "# get column names(17 out of which latter 14 are class labels)\n",
        "cols = dataset.columns.ravel()\n",
        "\n",
        "# reading features file\n",
        "label_features = []\n",
        "for i in range(3, 17):\n",
        "    sheet = cols[i]\n",
        "    feature = pd.read_excel(\"output_new.xlsx\", sheet_name=sheet)\n",
        "    label_features.append(feature)\n",
        "\n",
        "# alternate creation of dataframe(with 31 columns)\n",
        "columns = []\n",
        "for i in range(3, 17):\n",
        "    col_name = \"score_\" + cols[i]\n",
        "    columns.append(col_name)\n",
        "dataset[columns] = dataset['desc'].head(500).apply(score, label_features = label_features, cols = cols, stopwords = stopwords).apply(pd.Series)\n",
        "#print(dataset.columns.ravel())\n",
        "#print(dataset.head())\n",
        "df = dataset.head(500)\n",
        "\n",
        "# split dataset into training and testing modules\n",
        "# Split the dataframe into two separate dataframes\n",
        "label_df = df.iloc[:, :17]\n",
        "tfidf_df = df.iloc[:, 17:]\n",
        "\n",
        "# Split the data into a training set and a test set\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_class_counts = train_df.iloc[:, 3:17].sum()\n",
        "test_class_counts = test_df.iloc[:, 3:17].sum()\n",
        "\n",
        "print(\"Train class counts:\\n\", train_class_counts)\n",
        "print(\"Test class counts:\\n\", test_class_counts)\n",
        "\n",
        "# Convert the label columns into binary indicator variables\n",
        "binarizer = MultiLabelBinarizer()\n",
        "y_train = binarizer.fit_transform(train_df.iloc[:, 3:17].values)\n",
        "y_test = binarizer.transform(test_df.iloc[:, 3:17].values)\n",
        "\n",
        "# Use the pre-calculated tf-idf scores as input features for your model\n",
        "X_train_tfidf = train_df.iloc[:, 17:].values\n",
        "X_test_tfidf = test_df.iloc[:, 17:].values\n",
        "\n",
        "# Apply binary relevance by training a separate binary classifier for each label column\n",
        "classifiers = []\n",
        "for i in range(14):\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(X_train_tfidf, y_train[:, i])\n",
        "    classifiers.append(clf)\n",
        "\n",
        "# Evaluate the performance of the model on the test set\n",
        "y_pred = []\n",
        "for clf in classifiers:\n",
        "    y_pred.append(clf.predict(X_test_tfidf))\n",
        "y_pred = np.array(y_pred).T\n",
        "y_pred = binarizer.inverse_transform(y_pred)\n",
        "y_true = binarizer.inverse_transform(y_test)\n",
        "\n",
        "# Compute the accuracy of the model\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
